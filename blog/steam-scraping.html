<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Luka Krsnik</title>
    <link rel="shortcut icon" href="../static/favicon.ico">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="crossorigin"/>
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap"/>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap" media="print" onload="this.media='all'"/>
    <noscript>
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap"/>
    </noscript>
    <link href="../static/css/font-awesome/css/all.min.css?ver=1.2.1" rel="stylesheet">
    <link href="../static/css/monokai.css?ver=1.2.1" rel="stylesheet">
    <link href="../static/css/mdb.min.css?ver=1.2.1" rel="stylesheet">
    <link href="../static/css/aos.css?ver=1.2.1" rel="stylesheet">
    <link href="../static/css/main.css?ver=1.2.1" rel="stylesheet">
    <noscript>
      <style type="text/css">
        [data-aos] {
            opacity: 1 !important;
            transform: translate(0) scale(1) !important;
        }
      </style>
    </noscript>
  </head>
  <body class="bg-light" id="top">
    <header class="d-print-none">
      <div class="container text-center text-lg-left">
        <div class="pt-4 clearfix">
          <h1 class="site-title mb-0"><a class="override-link" href="/">Luka Krsnik</a></h1>
          <div class="site-nav">
            <nav role="navigation">
              <ul class="nav justify-content-center">
                <li class="nav-item"><a class="nav-link" href="/#about" title="About"><span class="menu-title">About</span></a>
                </li>
<!--                <li class="nav-item"><a class="nav-link" href="#skills" title="Skills"><span class="menu-title">Skills</span></a>-->
<!--                </li>-->
<!--                <li class="nav-item"><a class="nav-link" href="#experience" title="Experience"><span class="menu-title">Experience</span></a>-->
<!--                </li>-->
<!--                <li class="nav-item"><a class="nav-link" href="#education" title="Education"><span class="menu-title">Education</span></a>-->
<!--                </li>-->
                <li class="nav-item"><a class="nav-link" href="/#blog" title="blog"><span class="menu-title">Blog</span></a>
                </li>
                <li class="nav-item"><a class="nav-link" href="/#portfolio" title="Portfolio"><span class="menu-title">Portfolio</span></a>
                </li>
<!--                <li class="nav-item"><a class="nav-link" href="#references" title="References"><span class="menu-title">References</span></a>-->
<!--                </li>-->
                <li class="nav-item"><a class="nav-link" href="/#contact" title="Contact"><span class="menu-title">Contact</span></a>
                </li>
              </ul>
            </nav>
          </div>
        </div>
      </div>
    </header>
    <div class="page-content">
      <div class="container">

        <div class="shadow-1-strong bg-white my-5" id="intro">
          <div class="bg-info text-white">
            <div class="cover bg-image" style="height: 350px;"><img src="../static/images/header-background.jpg"/>
              <div class="mask" style="background-color: rgba(0, 0, 0, 0.7);backdrop-filter: blur(2px); height: 350px;">
                <div class="text-center p-5">
                  <div class="header-bio mt-3">
                    <div data-aos="zoom-in" data-aos-delay="0">
                      <h2 class="h1">Blog: Scraping Steam with Scrapy</h2>
                      <h2 class="h5">2024/06/25</h2>
                    </div>
                  </div>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text">Data Extraction</div>
                    </div>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text">Scraping</div>
                    </div>
                  
                  <br>
                  <br>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text small"><i class="fas fa-tools"></i> Python</div>
                    </div>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text small"><i class="fas fa-tools"></i> SQL</div>
                    </div>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text small"><i class="fas fa-tools"></i> SQLite</div>
                    </div>
                  
                    <div class="mdc-chip-shown">
                      <div class="mdc-chip__text small"><i class="fas fa-tools"></i> Scrapy</div>
                    </div>
                  
                  <br>
                  <br>
                  <div class="header-social-big mb-3 d-print-none" data-aos="zoom-in" data-aos-delay="200">
                    <nav role="navigation">
                      <ul class="nav justify-content-center">
                        
                          <li class="nav-item"><a class="nav-link" href="https://github.com/lkrsnik/steam-scraper" title="Github page">
                            
                              <i class="fab fa-github"></i>
                            
                            <span class="menu-title sr-only">Github page</span></a>
                          </li>
                        

                      </ul>
                    </nav>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>



  <div class="shadow-1-strong bg-white my-5 p-5" id="contact">
    <div class="contant-section">
      <h2>Introduction</h2>
<p>This blog contains a revised and expanded guide on how to extract reviews, general game information, and news from Steam webpages using Scrapy. The code is available in a <a href="https://github.com/lkrsnik/steam-scraper">GitHub repository</a>. It's a fork and update of the code produced for an original guide, titled <a href="https://www.zyte.com/blog/scraping-the-steam-game-store-with-scrapy/">Scraping the Steam game store with Scrapy</a>, which has become slightly outdated due to changes on the Steam website. I'd like to thank the author of initial blog post for an introduction to Scrapy and a great starting point for this project. The original code with fixes is available in a <a href="https://github.com/lkrsnik/steam-scraper/tree/updated_original">separate branch</a>.</p>
<h3>Why scraping?</h3>
<p>The world wide web is filled with data. While some of it is gathered into datasets or available through APIs, most exist only in publicly available HTML format. This is why I had this skill on my to-learn list. It's a powerful tool for creating new datasets from scratch and enriching existing ones.</p>
<h3>Legal and ethical considerations</h3>
<p>Web scraping isn't inherently illegal, but it's not always encouraged by website owners. It becomes illegal if scraping is explicitly prohibited in website terms of service. Many websites also have a file named <code>robots.txt</code>. This file instructs bots on how to interact with the website. Disrespecting it isn't necessarily illegal, but it's considered unethical.</p>
<p>I found no prohibitions (or express allowance) of scraping in Steam's terms of agreement. According to their <a href="https://steamcommunity.com/robots.txt">robots.txt</a>, they are quite permissive with scraping public data, since they allow bots to access most of their website. They even provide <a href="https://steamcommunity.com/dev">APIs</a> for certain data. Using APIs is generally superior to scraping because APIs are usually more stable and reliable way to access data.</p>
<h3>How to read this blog?</h3>
<p>As mentioned, this blog is an update to the slightly outdated <a href="https://www.zyte.com/blog/scraping-the-steam-game-store-with-scrapy/">original guide</a>. I suggest that you read the original since it explains some basic Scrapy concepts like crawlers and item loaders. This blog will focus on concepts that I found important and either weren't explained or not explained in enough detail for my scraping. I'll assume you're familiar with concepts covered in the original guide and skip explanations already provided there.</p>
<p>The content is split into two parts. The first part describes the fixes applied to the outdated code from the original guide. The second part expands the original code by adding a database and using web API to gather news.</p>
<h2>Code adaptations</h2>
<h3>Scrapy middlewares</h3>
<p>I try to think of Scrapy as a well-oiled machine. It is designed to do the scraping for you, with minimal input. To do that, you have to understand the <a href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-scheduler">architecture</a>, so that you know which setting or function to modify. </p>
<p>Middlewares are frameworks of hooks designed to plug custom functionality. There are two different middlewares, spider middleware, and downloader middleware. Their main intent is to preprocess requests before they get to the spider/downloader and postprocess the responses.</p>
<p>To use middlewares, you need to adjust the <code>SPIDER_MIDDLEWARES</code> or <code>DOWNLOADER_MIDDLEWARES</code> setting. These are dictionaries where the keys are the paths to your custom middleware classes, and the values are priority numbers that determine the order of execution. For preprocessing tasks (like adding headers), lower numbers are processed first. For postprocessing tasks (like cleaning data), higher numbers are processed first. </p>
<p>There are several built-in middlewares in Scrapy. You can find information about them in <a href="https://docs.scrapy.org/en/latest/topics/settings.html#std-setting-SPIDER_MIDDLEWARES_BASE">SPIDER_MIDDLEWARES_BASE</a> and <a href="https://docs.scrapy.org/en/latest/topics/settings.html#std-setting-DOWNLOADER_MIDDLEWARES_BASE">DOWNLOADER_MIDDLEWARES_BASE</a> settings. You may disable certain built-in middleware by setting its key to <code>None</code>.</p>
<h4>Example</h4>
<p>Steam's age verification process has been updated, causing the original code to frequently return <code>TypeError: Request url must be str, got NoneType</code>. This error occurred because the original approach relied on handling redirects for age confirmation that were modified. Instead, I found it easier to add the necessary cookie to each request. To achieve this, a new downloader middleware named <code>AddAgeCheckCookieMiddleware</code> was created.</p>
<p>We add this middleware to the <code>steam/settings.py</code> file with priority of 652:</p>
<div class="highlight"><pre><span></span><code><span class="n">DOWNLOADER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;steam.middlewares.AddAgeCheckCookieMiddleware&quot;</span><span class="p">:</span> <span class="mi">652</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>

<p>This priority is assigned, because we want this middleware to be triggered before the built-in <code>CookiesMiddleware</code>, which manages other cookies received from the web server (list of default priority numbers is shown in <a href="https://docs.scrapy.org/en/latest/topics/settings.html#std-setting-DOWNLOADER_MIDDLEWARES_BASE">DOWNLOADER_MIDDLEWARES_BASE</a>). </p>
<p>The code for the middleware is located in <code>steam/middlewares.py</code>:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">AddAgeCheckCookieMiddleware</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">process_request</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">spider</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;products&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">request</span><span class="o">.</span><span class="n">cookies</span><span class="p">:</span>
            <span class="n">request</span><span class="o">.</span><span class="n">cookies</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;wants_mature_content&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;lastagecheckage&quot;</span><span class="p">:</span> <span class="s2">&quot;1-0-1985&quot;</span><span class="p">,</span> <span class="s2">&quot;birthtime&quot;</span><span class="p">:</span> <span class="s1">&#39;470703601&#39;</span><span class="p">}</span>
</code></pre></div>

<p>There are <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#writing-your-own-downloader-middleware">various entry points</a> for customization of Scrapy middlewares. In this case, we use the <code>process_request</code> method to modify the request object before it's sent to Steam's servers.</p>
<h3>Other adaptations</h3>
<h4>Deprecated code</h4>
<p>Some Scrapy functions used in the original code have been deprecated. They are still functional but might be removed in future Scrapy versions. To address this, we need to replace the following line in <code>steam/items.py</code> file:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">scrapy.loader.processors</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Join</span><span class="p">,</span> <span class="n">MapCompose</span><span class="p">,</span> <span class="n">TakeFirst</span>
</code></pre></div>

<p>with:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">itemloaders.processors</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Join</span><span class="p">,</span> <span class="n">MapCompose</span><span class="p">,</span> <span class="n">TakeFirst</span>
</code></pre></div>

<h4>Adapted fields</h4>
<p>Several fields required adjustments due to changes on the Steam website. You'll find the details of these modifications in the <a href="https://github.com/prncc/steam-scraper/compare/master...lkrsnik:steam-scraper:updated_original">commit changes</a> for the following files:</p>
<ul>
<li><code>steam/spiders/product_spider.py</code></li>
<li><code>steam/spiders/review_spider.py</code></li>
<li><code>steam/items.py</code></li>
</ul>
<p>A quick summary of changes:</p>
<ul>
<li>I was scraping from Europe, which is why the code was adapted to handle prices in EUR with comma separators. If you have different currency format, you might need to adjust the <code>str_to_float</code> function in <code>steam/items.py</code>.</li>
<li>Rearranged divs within <code>specs</code>.</li>
<li><code>n_reviews</code> has been modified and now doesn't contain text "reviews" at the end.</li>
<li>New fields <code>description_about</code>, <code>description_reviews</code>, and <code>found_awarding</code> were added, while <code>found_unhelpful</code> was removed.</li>
<li>The code can now handle two <code>user_id</code> formats - <code>.*/profiles/&lt;PROFILE_ID&gt;/</code> and <code>.*/id/&lt;PROFILE_ID&gt;/</code></li>
<li>The scraper ignores broken review URLs like <a href="http://steamcommunity.com/app/1256/reviews/?browsefilter=mostrecent&amp;p=1">http://steamcommunity.com/app/1256/reviews/?browsefilter=mostrecent&amp;p=1</a>.</li>
</ul>
<h2>Extending scraper</h2>
<h3>SQLite database</h3>
<p>I wanted to store scraped data in a relational database because it is one of the most established and widely used methods for data storage and management. SQLite is a popular choice for such tasks, especially when dealing with projects that don't require a large-scale database server. I prefer this SQL database engine mostly because it is self-contained - meaning that it has very few dependencies and runs on any operating system with almost no use of external libraries. Put simply, it is easy to install and use. </p>
<h4>Schema</h4>
<p>The code that handles database connection and SQL queries is located in <code>steam/sqlite.py</code>. After examining the JSON files from the original code, I designed the following database schema:</p>
<p align="center">
  <img width="650" src="../../../static/images/scraping/schema.png">
</p>

<h4>Storing data into tables</h4>
<p>While I won't delve into every detail, here's a high-level overview of the main tables and their relationships, reflecting the three sources used:</p>
<ul>
<li><strong>Product tables</strong> - The central table <code>product</code> stores information about games and applications on Steam. Other tables that are strongly related to this one are <code>tag</code>, <code>genre</code> and <code>spec</code>.</li>
<li><strong>Review tables</strong> - The <code>review</code> table stores data extracted from Steam product reviews. Each user in Steam can post one review for one product. Reviews themselves don't have unique Steam keys, but they can be uniquely identified by combining user ID and product ID. However, in our database, we assign a new unique key for every review to simplify data manipulation within our application. We also maintain a separate <code>user</code> table to store some basic user information.</li>
<li><strong>News tables (explained later)</strong> - These include <code>news</code> and <code>ntag</code> tables used to store news published by authors of the product.</li>
</ul>
<h4>Tables related to scraping</h4>
<p>Scraping products typically takes a few hours, while reviews can take considerably longer, especially on single machine. To handle potential interruptions, a mechanism was implemented, that resumes review scraping from the last known point.</p>
<p>Here's how it works:</p>
<ul>
<li>When we access a URL for reviews, we receive a response containing a batch of reviews along with a link to the next batch.</li>
<li>Each review is stored in the <code>review</code> table, while information about the scraped batch, including the link to it, is stored in the <code>rscrape</code> table.</li>
<li>When a product's reviews are fully scraped (indicated by the absence of a "next batch" link), a <code>reviews_scraped</code> value in the <code>product</code> table is set to the current date and time. This timestamp helps identify completed products.</li>
</ul>
<p>This mechanism enables us to skip scraping products that were already processed by checking the <code>reviews_scraped</code> value. It also allows us to resume from the most recent batch retrieved before interruption, by looking for the latest entry in <code>rscrape</code> table, related to unfinished product.</p>
<p>While Steam's pagination system might appear to use standard parameters like <code>itemspage</code> and <code>numperpage</code>, these are actually irrelevant. Instead, Steam relies on a custom cursor system for navigating review pages. This means you need to use the specific cursor value provided by the previous page in <code>userreviewcursor</code> parameter to access the next one. Because the data might change while we scrape, it is possible that we get cursor that is invalid. In that case, we have to repeat scraping for the whole product. Since this issue is rare, I did not address it further and am ok with some products not being scraped completely.</p>
<h3>Scrapy pipelines</h3>
<p>In Scrapy, <a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">item pipelines</a> are designed for post-processing scraped data. They operate on each item extracted by the spider, allowing you to perform various tasks after the core scraping logic. Common use cases for item pipelines include cleaning, validation, deduplication and storage in databases.</p>
<p>Similar to middlewares, item pipelines are activated through an <code>ITEM_PIPELINES</code> setting. This is a dictionary where keys are the paths to your custom pipeline classes and the values are priority numbers that determine the order of execution. This allows you to chain multiple pipelines together to perform a sequence of post-processing steps. </p>
<h4>Example</h4>
<p>In the <code>steam/settings.py</code> file, we include the following setting to activate the <code>SQLitePipeline</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s1">&#39;steam.pipelines.SQLitePipeline&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>

<p>The function that is responsible for processing scraping result is called <code>process_item</code>. In our case, this is where we store data into the database:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SQLitePipeline</span><span class="p">:</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">spider</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;products&#39;</span><span class="p">:</span>
            <span class="n">spider</span><span class="o">.</span><span class="n">db</span><span class="o">.</span><span class="n">add_product</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">spider</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;reviews&#39;</span><span class="p">:</span>
            <span class="n">spider</span><span class="o">.</span><span class="n">db</span><span class="o">.</span><span class="n">add_review</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()),</span> <span class="n">spider</span><span class="o">.</span><span class="n">review_ids</span><span class="p">,</span> <span class="n">spider</span><span class="o">.</span><span class="n">rscrape_ids</span><span class="p">,</span> <span class="n">spider</span><span class="o">.</span><span class="n">user_ids</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">item</span>
</code></pre></div>

<p>The function checks the spider name and calls the appropriate method to add product or review to the database. The <a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">Scrapy documentation</a> provides more details on pipeline functionality. </p>
<h3>Using a web api for news</h3>
<p>The <a href="https://steamcommunity.com/dev">Steam Web API</a> allows you to fetch various kinds of product data, including user stats, user information and product news. While an API key is typically required for most functionalities, fetching news appears to be an exception, as documented in <a href="https://developer.valvesoftware.com/wiki/Steam_Web_API#GetNewsForApp_.28v0002.29">detailed documentation</a>.</p>
<h4>Example</h4>
<p>The script for fetching news using the Steam Web API is located in <code>scripts/get_news_api.py</code>. This script is typically run after scraping reviews, because it retrieves news for products that already have reviews in the database.</p>
<p>Here's the core section of the script that downloads and stores news data:</p>
<div class="highlight"><pre><span></span><code><span class="n">url_string</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;http://api.steampowered.com/ISteamNews/GetNewsForApp/v0002/?appid=</span><span class="si">{</span><span class="n">product_id</span><span class="si">}</span><span class="s2">&amp;count=20000&amp;maxlength=20000&amp;format=json&quot;</span>
<span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url_string</span><span class="p">)</span> <span class="k">as</span> <span class="n">url</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;appnews&#39;</span><span class="p">][</span><span class="s1">&#39;newsitems&#39;</span><span class="p">]:</span>
        <span class="n">db</span><span class="o">.</span><span class="n">add_news</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span>
    <span class="n">db</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</code></pre></div>

<h2>Conclusion</h2>
<p>The blog post builds upon the original blog by identifying and correcting sections of code required to get the scraper functioning again. It expands on the original code by including additional news data and storing it by using Scrapy pipelines and SQLite database.</p>
<p>If you're looking for debugged code only, you can access it on <a href="https://github.com/lkrsnik/steam-scraper/tree/updated_original"><code>updated_original</code></a> branch. The complete code is available on the <a href="https://github.com/lkrsnik/steam-scraper/"><code>master</code></a> branch.</p>
<p>I hope this revised version proves helpful to those who encountered issues with the original scraping code. My experience with Scrapy has been very educational. I've gained a deeper understanding of the challenges associated with scraping and the advantages of using APIs.</p>
<p>This is the first actual blog I have ever written, so if you have any suggestions, or you found some explanations lacking, please let me know!</p>
    </div>
  </div>
</div></div>
    </div>
    <footer class="pt-4 pb-4 text-muted text-center d-print-none">
      <div class="container">
        <div class="my-3">
          <div class="h4"><a class="override-link" href="/">Luka Krsnik</a></div>
          <div class="footer-nav">
            <nav role="navigation">
              <ul class="nav justify-content-center">
                <li class="nav-item"><a class="nav-link" href="https://www.linkedin.com/in/luka-krsnik-6b9a4a156/" title="LinkedIn"><i class="fab fa-linkedin"></i><span class="menu-title sr-only">LinkedIn</span></a>
                </li>
                <li class="nav-item"><a class="nav-link" href="https://github.com/lkrsnik" title="Github"><i class="fab fa-github"></i><span class="menu-title sr-only">Github</span></a>
                </li>
              </ul>
            </nav>
          </div>
        </div>
        <div class="text-small">
          <div class="mb-1">&copy; 2023 Luka Krsnik</div>
          <div>Design - <a href="https://templateflip.com/" target="_blank">TemplateFlip</a></div>
        </div>
      </div>
    </footer>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"> </script>
    <script src="../static/scripts/mdb.min.js?ver=1.2.1"></script>
    <script src="../static/scripts/aos.js?ver=1.2.1"></script>
    <script src="../static/scripts/generic.js?ver=1.2.1"></script>
  </body>
</html>